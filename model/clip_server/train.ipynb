{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599aadc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2447300a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4f9e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb7a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandmarkDataset(Dataset):\n",
    "    def __init__(self, csv_path, images_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.label2idx = {label: idx for idx, label in enumerate(sorted(self.data['landmark_id'].unique()))}\n",
    "        self.data['label'] = self.data['landmark_id'].map(self.label2idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        img_path = os.path.join(self.images_dir, row['name'] + \".jpg\")\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = row['label']\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c0db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4b270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1bfd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "\n",
    "    def step(self, val_score):\n",
    "        if self.best_score is None or val_score > self.best_score:\n",
    "            self.best_score = val_score\n",
    "            self.counter = 0\n",
    "            return False  # No early stop\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            return self.counter >= self.patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc38ffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, optimizer, criterion, epochs, device):\n",
    "    early_stopper = EarlyStopping(patience=3)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, total, correct = 0, 0, 0\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for x, y in loop:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "            loop.set_postfix(loss=total_loss/total, acc=100*correct/total)\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_loss = total_loss / total\n",
    "        val_acc = evaluate(model, val_loader, device)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Acc = {train_acc:.4f}, Val Acc = {val_acc:.4f}\")\n",
    "\n",
    "        mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "        mlflow.log_metric(\"train_acc\", train_acc, step=epoch)\n",
    "        mlflow.log_metric(\"val_acc\", val_acc, step=epoch)\n",
    "\n",
    "        if early_stopper.step(val_acc):\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24984c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_csv = \"train.csv\"\n",
    "val_csv = \"val.csv\"\n",
    "# test_csv = \"test.csv\"\n",
    "image_dir = \"images\"\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "num_classes = len(train_dataset.label2idx)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "base_model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "in_features = base_model.classifier[1].in_features\n",
    "base_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.4),\n",
    "    nn.Linear(in_features, 512),\n",
    "    nn.Dropout(p=0.4),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, num_classes)\n",
    ")\n",
    "model = base_model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4,weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d5b079",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"landmark-efficientnet\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model\", \"efficientnet_b0\")\n",
    "    mlflow.log_param(\"epochs\", 100)\n",
    "    mlflow.log_param(\"batch_size\", 32)\n",
    "    mlflow.log_param(\"learning_rate\", 1e-4)\n",
    "\n",
    "    train(model, train_loader, val_loader, optimizer, criterion, epochs=100)\n",
    "\n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), \"efficientnet_b0_landmark.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9aa3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8147b2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
